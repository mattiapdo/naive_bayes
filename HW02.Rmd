---
title: "Homework 2"
author: "Mattia Podio"
date: "24 maggio 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#rm(list = ls())
```

### Load Data and Look at Them

We will perform analysis on data from sensors placed as 5 different units on the body 

(*T* Torso, 
*RA* Rigth Arm,
*LA* Left Arm,
*RL* Right Leg,
*LL* Left Leg) 

of a person, while he was performing several activities.

```{r}
load(file = 'daily-sport.RData')
```

The activities are: 'walking', 'stepper', 'crosstr' and 'jumping', and there are 7500 observations for each class...

```{r}
table(dailysport$id)
```

Each sensor measure a specific quantity in the tree dimesional space, in particular:

- acceleration (x,y,z)

- radial acceleration (x,y,z)

- magnetic field (x,y,z)

Each feature is numerical, and there are no NAs:

```{r}
str(dailysport)
```

```{r}
cat('NAs:',sum(is.na(dailysport)))
```

Let's reduce the dataset to two activities and drop the unused levels ('jumping' and 'walking').

This dataset is called 'ds.small', and contains just 3 sensors on one location
 
```{r}
? subset
```

 
```{r}
ds.small = subset(x = dailysport, subset = id == "crosstr" | id == "stepper", select = c("id","RL-xMag","RL-yMag","RL-zMag"))
table(ds.small$id)

# drop unused levels:
ds.small = droplevels(ds.small)
table(ds.small$id)

colnames(ds.small) = c("id", "RLxMag", "RLyMag", "RLzMag")
str(ds.small)
```

```{r, echo = F, eval = F}
library(plotly)
```

Plot 500 points in ds.small choosen at random, treating them as 3-dimensional data points

```{r}
p <- plot_ly(ds.small[sample(x = 1:nrow(ds.small), size = 500, replace = F) ,], 
             x = ~RLxMag, y = ~RLyMag, z = ~RLzMag, color = ~id, colors = c('lightpink', 'magenta')) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'RL-xMag'),
                     yaxis = list(title = 'RL-yMag'),
                     zaxis = list(title = 'RL-xMag')))
p
```

Split ds.small in ds.train and ds.test containing 70% and 30% of the original dataset respectively
Before splitting we standardize

```{r}

library(MASS)
library(vegan)

#Standardize 'em all  before splitting the dataset
num_attr = c("RLxMag", "RLyMag", "RLzMag")
num_var = ds.small[,num_attr]
num_stand = decostand(num_var, "standardize")
sel = subset(ds.small,subset = id == "crosstr" | id == "stepper",select = c("id"))
#The data set normalized
ds.stand = cbind(sel,num_stand)

 
```
Now we can split!



```{r}
## 70% of the sample size
sample_size =floor(0.70 * nrow(ds.small))

## set the seed to make the partition reproducible
set.seed(123)
#Mix the indices
intrain=sample(seq_len(nrow(ds.stand)), size = sample_size)
#Derive the sets!
ds.train = ds.stand[intrain, ]
ds.test  = ds.stand[-intrain, ]
```

Perform LDA


```{r}
#Perform the LDA on data on the final dataset we created
lda.out <- lda(formula = id ~ ., 
         data = ds.train, 
         prior = c(1,1)/2)
#Predictions for the train (final) and the test dataset

pred.test = predict(object = lda.out, # predictions
               newdata = ds.test)$class


pred.train = predict(object = lda.out, # predictions
                    newdata = ds.train)$class

#accuracy on training data
mean(pred.train == ds.train$id)


#accuracy on test data
mean(pred.test == ds.test$id)


#Classifier prediction
table(pred.test)


#Initial values
table(pred.train)



#head(plda$class) # classification result
#head(plda$posterior, 3) # posterior prob.
#head(plda$x, 3) # LD projections





#See the posterior probabilities calculated by LDA

r2 <- lda(formula = id ~ ., 
          data = ds.train, 
          prior = c(1,1)/2,
          CV = TRUE)

head(r2$class)
head(r2$posterior, 3)



```

Comme te non c'e nessuno!

Bastardo infame per te solo le lame!
